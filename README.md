# Multi-Agent Research Assistant

**Real web search + AI APIs + PDF analysis in one simple file.**

## ğŸŒ **Real Web Integration**

- **Live Web Search**: DuckDuckGo, Wikipedia, arXiv, Reddit APIs
- **Content Extraction**: Real websites with BeautifulSoup
- **AI Summarization**: OpenAI GPT-3.5/4 integration
- **PDF Processing**: PyMuPDF/PyPDF2 for document analysis
- **Fallback System**: Mock data when APIs are unavailable

## ğŸš€ Quick Start

1. **Install:**
```bash
pip install aiohttp beautifulsoup4 requests PyPDF2 openai
```

2. **Set API Key (Optional):**
```bash
export OPENAI_API_KEY="your_openai_key_here"
```

3. **Run:**
```bash
python main.py
```

## ğŸ”— **API Integrations**

### **Web Search APIs:**
- **DuckDuckGo Instant Answers** - No API key needed
- **Wikipedia REST API** - Free, no limits
- **arXiv API** - Academic papers, free access
- **Reddit JSON API** - Community discussions

### **AI Services:**
- **OpenAI GPT-3.5/4** - Intelligent summarization
- **Fallback**: Extractive summarization without AI

### **Content Sources:**
- **Live websites** - Real-time content extraction
- **Academic papers** - arXiv integration
- **PDF documents** - Local file processing
- **Social discussions** - Reddit insights

## ğŸ’¡ **Advanced Usage**

### **With OpenAI API:**
```python
import os
os.environ['OPENAI_API_KEY'] = 'your_key_here'

assistant = ResearchAssistant()
results = await assistant.research(
    query="machine learning healthcare applications",
    pdf_files=["research_paper.pdf"],
    max_web_results=10
)

# Gets AI-powered summary + real web data
```

### **Without APIs (Free Mode):**
```python
# Works without any API keys
assistant = ResearchAssistant()
results = await assistant.research(
    query="artificial intelligence trends",
    max_web_results=5
)

# Uses extractive summarization + free APIs
```

## ğŸ“Š **Real Data Sources**

The system automatically searches:

1. **ğŸ¦† DuckDuckGo** - Instant answers and topics
2. **ğŸ“š Wikipedia** - Comprehensive articles  
3. **ğŸ“ arXiv** - Academic research papers
4. **ğŸ’¬ Reddit** - Community discussions
5. **ğŸŒ Live Websites** - Real content extraction
6. **ğŸ“„ PDF Files** - Your local documents

## ğŸ¯ **Example Output**

```
ğŸ”¬ Multi-Agent Research Assistant
ğŸ” Searching web for: quantum computing applications
   âœ… Found 3 DuckDuckGo results
   âœ… Found 1 Wikipedia article  
   âœ… Found 2 arXiv papers
   âœ… Extracted content from 6 websites
ğŸ¤– OpenAI API available for AI summarization
ğŸ“ Creating AI-powered summary
ğŸ“Š Generating comprehensive report

âœ… Research Complete!
ğŸ“ Task ID: abc123
ğŸŒ Web sources: 6 (5 real + 1 fallback)
ğŸ“„ PDF sources: 0
ğŸ“‚ Check: outputs/task_abc123/
```

## ğŸ“ **Rich Output Files**

Each research creates:
```
outputs/task_abc123/
â”œâ”€â”€ report.md        # Full research report
â”œâ”€â”€ summary.md       # AI/extractive summary
â””â”€â”€ results.json     # Complete structured data
```

## ğŸ”§ **API Configuration**

### **Required (Free):**
- âœ… DuckDuckGo API - No key needed
- âœ… Wikipedia API - No key needed  
- âœ… arXiv API - No key needed
- âœ… Reddit JSON - No key needed

### **Optional (Enhanced):**
```bash
# For AI summarization
export OPENAI_API_KEY="sk-..."

# For Google Search (if you want to add it)
export GOOGLE_API_KEY="your_key"
export GOOGLE_CSE_ID="your_cse_id"
```

## ğŸš€ **Features**

### **Smart Web Search:**
- Multi-API approach for comprehensive coverage
- Automatic content extraction from websites
- Source diversity (academic + general + discussions)
- Relevance scoring and filtering

### **AI Integration:**
- OpenAI GPT for intelligent summarization
- Context-aware analysis across sources
- Professional report generation
- Fallback to extractive methods

### **PDF Analysis:**
- Advanced text extraction (PyMuPDF/PyPDF2)
- Key point identification  
- Section analysis
- Error handling for encrypted/corrupted files

### **Professional Output:**
- Markdown reports with proper formatting
- Source attribution and links
- Research statistics and insights
- JSON data for further processing

## ğŸ› ï¸ **Troubleshooting**

### **No results found?**
```bash
# Check internet connection
ping google.com

# Install all dependencies  
pip install aiohttp beautifulsoup4 requests PyPDF2 openai lxml
```

### **API errors?**
- DuckDuckGo/Wikipedia are free - no setup needed
- OpenAI requires valid API key for AI features
- System works without OpenAI (uses extractive summarization)

### **PDF processing fails?**
```bash
# Install better PDF library
pip install PyMuPDF

# Or ensure PyPDF2 is updated
pip install --upgrade PyPDF2
```

## ğŸ¯ **Real vs Mock Data**

The system intelligently uses:
- **Real APIs first** - Live data from DuckDuckGo, Wikipedia, etc.
- **Smart fallback** - Mock data only when real APIs fail
- **Transparent reporting** - Shows source of each result
- **Quality metrics** - Relevance scores for all content

## ğŸ“ˆ **Scaling Up**

To add more APIs:
```python
# Add to WebAgent._search_real_web()
google_results = await self._search_google(query, max_results//4)
results.extend(google_results)

# Add to WebAgent  
async def _search_google(self, query, max_results):
    # Your Google Custom Search implementation
    pass
```

## ğŸ’¡ **Pro Tips**

1. **Set OpenAI key** for best summaries
2. **Use specific queries** for better results  
3. **Include PDFs** for comprehensive analysis
4. **Check source diversity** in outputs
5. **Customize APIs** in WebAgent class

---

**Real APIs â€¢ AI Integration â€¢ Professional Output â€¢ One Simple File** âš¡# Multi-Agent Research Assistant

**Simple, powerful research automation in one file.**

## ğŸš€ Quick Start

1. **Install:**
```bash
pip install aiohttp beautifulsoup4 requests PyPDF2
```

2. **Run:**
```bash
python main.py
```

That's it! ğŸ‰

## ğŸ“‹ What It Does

- **Web Search**: Finds relevant articles and content
- **PDF Analysis**: Extracts text and key points from PDFs  
- **Smart Summary**: Creates comprehensive research summaries
- **Professional Reports**: Generates markdown reports

## ğŸ’¡ Usage

```python
import asyncio
from main import ResearchAssistant

async def research():
    assistant = ResearchAssistant()
    
    results = await assistant.research(
        query="your research topic here",
        pdf_files=["document.pdf"],  # optional
        max_web_results=8
    )
    
    print(f"Done! Check: outputs/task_{results['task_id']}/")

asyncio.run(research())
```

## ğŸ“ Output

Each research task creates:
- `report.md` - Full research report
- `summary.md` - Executive summary  
- `results.json` - Complete data

## ğŸ”§ Optional Features

**For PDF support:**
```bash
pip install PyMuPDF  # Better quality
# OR
pip install PyPDF2   # Lighter weight
```

**For AI summarization:**
```bash
pip install openai
# Set OPENAI_API_KEY environment variable
```

## ğŸ¯ Example Output

```
ğŸ”¬ Multi-Agent Research Assistant
========================================
INFO: ğŸ” Searching web for: artificial intelligence in healthcare
INFO: ğŸ“ Creating summary for 3 web + 0 PDF sources
INFO: ğŸ“Š Generating report for: artificial intelligence in healthcare
INFO: ğŸ’¾ Results saved to: outputs/task_a1b2c3d4

âœ… Research Complete!
ğŸ“ Task ID: a1b2c3d4
ğŸŒ Web sources: 3
ğŸ“„ PDF sources: 0
ğŸ“‚ Check: outputs/task_a1b2c3d4/
```

## ğŸ› ï¸ Troubleshooting

**Import errors?**
```bash
pip install -r requirements.txt
```

**No PDF support?**
```bash
pip install PyMuPDF
```

**Want better web search?**
- The current version uses mock search results
- Replace `WebAgent.search()` with real API calls (Google, Bing, etc.)

---

**Everything in one file. No complexity. Just results.** âš¡